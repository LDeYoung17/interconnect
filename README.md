# interconnect

<h2>Summary</h2>

This project provides data analysis and evaluates multiple machine learning models, both with and without gradient boosting, in order to make recommendations to a media company about how to best predict customer churn and make plans to retain customers.

<h2>Table of Contents</h2>

      1. Exploratory Data Analysis(notebooks > EDA.ipynb)
            a) Package installation
            b) Library importation
            c) Import the data
            d) Data preprocessing - includes removing extraneous HTML tags
            e) Merging datasets into one dataframe
            f) EDA
            g) Data cleaning
            h) Create a new CSV
      
      2. Machine Learning Models (notebooks > ML.ipynb)
            
            a) Package installation
            b) Library importation
            c) Import the data
            d) Split the data
            e) Create vectors/embeddings
            f) Create the model
            g) Create the pipeline
            h) Query based on the trained model

      3. Application (app.py)
            a) Library Importations
            b)The initial part of this file (cl.on_chat_start) is the same as ML.ipynb
            c) The second part of this file (cl.on_message) is the part of the application where the chatbot responds to a question asked.
      

<h2>Local Access</h2>

This project will require Python 3.11.5 or later (if available).

All packages required can be installed from the requirements.txt file by executing the command 'pip install -r requirements.txt' from the CLI.

To run the Jupyter notebooks, they can be downloaded from the repository and run in the IDE of your choice that can accommodate.


<h2>Plans for Updates</h2>

There are no plans for updates at this time.

<h2>Sample Graph</h2>

![image](https://github.com/LDeYoung17/interconnect/assets/70500225/080a65b8-66ee-4f80-8577-bca4e36df2e3)


<h2>Portfolio Link</h2>

https://ldeyoung17.github.io/

This is my portfolio where all my projects, including this one, can be found, as well as more information about my experience as a Data Scientist and Software Engineer.


